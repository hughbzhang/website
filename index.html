<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hugh Zhang</title>
  
  <meta name="author" content="Hugh Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hugh Zhang</name>
              </p>
              <p>I am currently on leave from Harvard and working as a student researcher on the Bard team at Google Deepmind. Usually, I am a PhD candidate in the Harvard EconCS group, where I am advised by <a href="https://parkes.seas.harvard.edu/"> David Parkes </a> and supported by the <a href="https://www.nsfgrfp.org/"> NSF Graduate Research Fellowships Program </a> and a <a href="https://www.harvard.edu/kempner-institute/"> Kempner Institute Graduate Fellowship</a>. Previously, I was a software engineer at <a href="https://asana.com/"> Asana </a> (gap year before college), studied Economics at Stanford, and have worked at <a href="https://research.google/teams/brain/"> Google Brain</a> and <a href="https://ai.facebook.com"> Meta AI </a>. 

              My current research interest revolves around teaching large language models to plan. Previously, I did similar work as part of the <a href="https://ai.facebook.com/research/cicero/"> <em>CICERO</em> </a> project, the first AI agent to achieve human-level performance in the game of <a href="https://en.wikipedia.org/wiki/Diplomacy_(game)"> Diplomacy </a>.
              <br><br>
              In my spare time, I've been a lifelong Go player (in fact, seeing <a href="https://www.nature.com/articles/nature16961"> AlphaGo </a> beat Lee Sedol was origin of my interest in AI). I also co-founded the <a href="https://twitter.com/gradientpub"> Gradient </a> , a digital magazine focusing on AI, and serve as its lead editor.
              </p>
              <p style="text-align:center">
           
                <a href="mailto:hughzhang@seas.harvard.edu">Email</a> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=CgZ9uJkAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/hughbzhang">Twitter</a> &nbsp/&nbsp
                <a href="https://www.goodreads.com/user/show/60478481-hugh-zhang">Goodreads</a> &nbsp/&nbsp
                <a href="https://github.com/hughbzhang/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/HughZhang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/PROFILE.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                In the past, I've been interested in multi-agent reinforcement learning, game theory, and language models. Much of my research is trying to figure out how to cram all three into one project. <strong>* denotes equal or alphabetical ordering.</strong>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SECToR.jpg" alt="SECToR" width="160" height="100%">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2309.08589">
                <papertitle>Chain-of-Thought Reasoning is a Policy Improvement Operator</papertitle>
              </a>
              <br>
              <strong>Hugh Zhang</strong>, <a href="TODO">David C. Parkes</a> 
              <br>
              <em>Workshop on Instruction Tuning and Instruction Following at NeurIPS 2023</em>
              <p>AlphaZero-like self-improvement for language models.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ABCs.jpg" alt="ABCs" width="160" height="100%">
            </td>
            <td width="75%" valign="middle">
              <a href="TODO">
                <papertitle>TODO</papertitle>
              </a>
              <br>
              <strong>Hugh Zhang</strong>, Luca, David
              <br>
              <p>A unified algorithm that can simulatenously solve both standard reinforcement learning environments (e.g. Cartpole) and standard game theory environments (e.g. Kuhn/Leduc Poker) using the exact same set of hyperparameters.</p>
            </td>
          </tr>

          <tr onmouseout="diplomacy_stop()" onmouseover="diplomacy_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='diplomacy_image'>
                  <video  width=100% muted autoplay loop>
                    <source src="images/DIPLOMACY.mp4" width="160" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <img src='images/DIPLOMACY.jpg' width="160">
              </div>
              <script type="text/javascript">
                function diplomacy_start() {
                  document.getElementById('diplomacy_image').style.opacity = "1";
                }

                function diplomacy_stop() {
                  document.getElementById('diplomacy_image').style.opacity = "0";
                }
                diplomacy_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.science.org/doi/10.1126/science.ade9097?fbclid=IwAR2Z3yQJ1lDMuBUyfICtHnWz2zRZEhbodBkAJlYshvxkCqpcYFhq5a_Cg6Q">
                <papertitle>Human-level play in the game of Diplomacy by combining language models with strategic reasoning</papertitle>
              </a>
              <br>
              Anton Bakhtin*, Noam Brown*, Emily Dinan*, Gabriele Farina*, Colin Flaherty*, Daniel Fried*, Andrew Goff*, Jonathan Gray*, Hengyuan Hu*, Athul Paul Jacob*, Mojtaba Komeili*, Karthik Konath*, Adam Lerer*, Mike Lewis*, Alexander H. Miller*, Sasha Mitts*, Adithya Renduchintala*, Stephen Roller*, Dirk Rowe*, Weiyan Shi*, Joe Spisak*, Alexander Wei*, David Wu*, <strong>Hugh Zhang*</strong>, Markus Zijlstra*
              <br>
              <em>Science</em>, 2022
              <br>
              <a href="data/diplomacy.pdf">paper</a>
              /
              <a href="https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/?utm_source=twitter&utm_medium=organic_social&utm_campaign=cicero&utm_content=video">blog</a>
              /
              <a href="https://www.nytimes.com/2023/01/20/technology/chatbots-turing-test.html"> nyt </a>
              /
              <a href="https://www.economist.com/science-and-technology/2022/11/23/another-game-falls-to-an-ai-player"> economist </a>
              /
              <a href="https://gizmodo.com/meta-ai-cicero-diplomacy-gaming-1849811840"> gizmodo </a>
              /
              <a href="https://www.forbes.com/sites/carlieporterfield/2022/11/22/metas-ai-gamer-beat-humans-in-diplomacy-using-strategy-and-negotiation/"> forbes </a> 
              /
              <a href="https://www.newscientist.com/article/2348152-metas-board-game-playing-ai-can-pass-as-a-human-in-game-negotiations/"> new scientist </a> 
              /
              <a href="https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/"> ars technica </a> 
              /
              <a href="https://www.technologyreview.com/2022/11/23/1063648/metas-game-playing-ai-can-make-and-break-alliances-like-a-human/">mit tech review </a> 
              /
              <a href="https://kotaku.com/facebook-meta-ai-artificial-intelligence-board-game-win-1849815368">kotaku</a> 
              /
              <a href="https://www.engadget.com/add-diplomacy-to-the-list-of-activities-ai-can-do-as-well-as-humans-140024906.html">engadget</a> 
              /
              <a href="https://www.theregister.com/2022/11/23/metas_cicero_chatbot_can_probably/">register </a> 
              /
              <a href="https://news.ycombinator.com/item?id=33706750"> hacker news </a>
              /
              <a href="https://www.reddit.com/r/MachineLearning/comments/z1yt45/r_humanlevel_play_in_the_game_of_diplomacy_by/"> reddit </a>
              <p></p>
              <p>
              Human level performance in the game of Diplomacy, where agents negotiate with other humans in natural language.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/GREEDY_WEIGHTS.jpg" alt="GREEDY_WEIGHTS" width="160" height="100%">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2204.04826">
                <papertitle>Equilibrium Finding in Normal-Form Games Via Greedy Regret Minimization</papertitle>
              </a>
              <br>
              <strong>Hugh Zhang</strong>, <a href="https://scholar.google.com/citations?user=Ad6O4-0AAAAJ&hl=en">Adam Lerer</a>, <a href="https://www.cs.cmu.edu/~noamb/">Noam Brown</a>, 
              <br>
              <em>Association for the Advancement of Artificial Intelligence (AAAI)</em>, 2022
              <p>A novel no-regret learning procedure that converges to correlated and coarse-correlated equilibria several orders of magnitude faster than previous methods in randomly generated normal-form games.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LIKELIHOOD_TRAP.jpg" alt="LIKELIHOOD_TRAP" width="160" height="100%">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2004.10450">
                <papertitle>Trading Off Diversity and Quality in Natural Language Generation</papertitle>
              </a>
              <br>
              <strong>Hugh Zhang*</strong>, <a href="https://www.stronglyconvex.com/about.html">Daniel Duckworth*</a>, <a href="https://www.seas.upenn.edu/~daphnei/me/">Daphne Ippolito</a>, <a href="https://scholar.google.com/citations?user=ygTCc6cAAAAJ&hl=en">Arvind Neelakantan</a> 
              <br>
              <em>Workshop on Human Evaluation of Natural Language Processing Systems at the Conference of the European Chapter of the Association for Computational Linguistics (HumEval Workshop @EACL)</em>, 2021
              <p>The first large-scale evaluation of decoding methods for large language models along the entire quality-diversity spectrum.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/FORGIVING_CORRELATED_EQUILIBRIA.jpg" alt="FORGIVING_CORRELATED_EQUILIBRIA" width="160" height=100%>
            </td>
            <td width="75%" valign="middle">
              <a href="https://economics.stanford.edu/simple-adaptive-procedure-converging-forgiving-correlated-equilibria">
                <papertitle>A Simple Adaptive Procedure Converging to Forgiving Correlated Equilibria</papertitle>
              </a>
              <br>
              <strong>Hugh Zhang</strong> (advised by <a href="http://individual.utoronto.ca/carroll/">Gabriel Carroll</a>)
              <br>
              <em>Stanford Senior Honors Thesis in Economics</em>, 2020 <font color="red"><strong>(John G. Sobieski Award for Creative Thinking)</strong></font>
              <p>Alongside <a href="https://arxiv.org/abs/2004.00603"> Celli et. al (2020) </a> (concurrent work), this paper gives the first internal regret minimization dynamics for extensive-form games.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/HUSE.jpg" alt="HUSE" width="160" height=100%>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1904.02792">
                <papertitle>Unifying Human and Statistical Evaluation for Natural Language Generation</papertitle>
              </a>
              <br>
              <a href="https://thashim.github.io/">Tatsunori Hashimoto* </a>, <strong>Hugh Zhang*</strong>, <a href="https://cs.stanford.edu/~pliang/">Percy Liang </a>
              <br>
              <em>North American Chapter of the Association for Computational Linguistics (NAACL)</em>, 2019  <font color="red"><strong>(Oral Presentation)</strong></font>
              <p>Existing language models can generate either high quality or diverse utterances, but not both simultaneously. How can we measure that in a single metric?</p>
            </td>
          </tr>

        </tbody></table>

				
        
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Thanks to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> for this website's template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
